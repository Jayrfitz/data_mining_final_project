---
title: "Student Alcohol Consumption"
author: "Antonio Soto, Andrew Diesh, Jason Fitzgerald"
date: "April 22, 2017"
output: html_document
---
  
```{r global_options, include=FALSE}
knitr::opts_chunk$set(prompt=TRUE, comment="", echo=TRUE)
```

###**Objective**
Given the tools and techniques learned throughout the past four months, we want to use these to analyze a dataset of our choosing and answer some questions using prediction models. We decided to work with the student alcohol consumption dataset, which focuses on alcohol consumption in Portugal. This data set was gathered during the 2005-2006 school year from a survey of students in a Portuguese language course from the Alentejo region of Portugal.Paulo Cortez and Alice Silva went on to use this dataset for their study, _Using Data Mining to Predict Secondary School Student Performance_. A questions we as a group are trying to explore is can we determine a passing grade for a student based off the amount of alcohol they consume on workdays and weekends, amount of absenses, and the other factors.The data was acquired from Kaggle, a data science platform, at https://www.kaggle.com/uciml/student-alcohol-consumption. 




```{r}
library(rpart)
library(rpart.plot)
library(maptree)
library(e1071)

# jason
# dat = read.csv("/Users/jasonfitzgerald/Desktop/463Data/MiningProject/student-por.csv", stringsAsFactors = T)
# source("/Users/jasonfitzgerald/Desktop/463Data/MiningProject/class-util.R")
# source("/Users/jasonfitzgerald/Desktop/463Data/MiningProject/lin-regr-util.R")
# andrew
dat = read.csv("/Users/AndrewDiesh/Desktop/student-por.csv", stringsAsFactors = T)
source("/Users/AndrewDiesh/Desktop/class-util.R") 
source("/Users/AndrewDiesh/Documents/CST\ 463/HW10/lin-regr-util.R")
# antonio
# dat = read.csv("C:/Users/Antonio S/Documents/College/CSUMB-Spring'17/CST463-DataMining/FinalPro/student-por.csv", stringsAsFactors = T)
# source("C:/Users/Antonio S/Documents/College/CSUMB-Spring'17/CST463-DataMining/FinalPro/class-util.R")
# source("C:/Users/Antonio S/Documents/College/CSUMB-Spring'17/CST463-DataMining/FinalPro/lin-regr-util.R")
set.seed(123)
```


###**Data Exploration**
Now that we have our data, we'll take a look at a few plots to see what data we're working with.

Our data revolves around secondary school students; therefore, it would be useful to take a look at what ages are represented.
```{r}
dat$pieAges = ifelse(dat$age >= 20, '+20', dat$age)
ageOfStudents= table(dat$pieAges)

lbs = c(paste (names(table(dat$pieAges)), '-', round(table(dat$pieAges)/nrow(dat)*100,digit= 1), '%'))

pie(ageOfStudents, labels= lbs, main = 'Student Ages')
```

Now that we have an understanding of the different age groups in the class, we would like to explore how many males and females are enrolled in the course. 


```{r}

table(dat$sex)
plot(dat$sex, main = "Student's Gender", col = "red4", ylim = c(0, 400))

```

We can see that there are more girls (383) taking the class than males (266). 

Our models will try to predict what the student's final grades will be.
Secondary and higher education in Portugal uses a 20-point grading scale.

18-20 indicates **excellent**, it's equivalent to an A+.

16-17.99 indicates **very good**, it's equivalent to an A.

14-15.99 indicates **good**, it's equivalent to a B.

10-13.99 indicates **sufficient**, it's equivalent to a C.

7-9.99 indicates **poor**, it's equivalent to an F.

1-6.99 indicates **very poor**, it's equivalent to an F.

Here we'll take a look at the grade distribution for male and female students. 

```{r}
par(mfrow=c(1, 2))
hist(dat[dat$sex=="M", ]$G3, main="Male Students' Final Grades", xlab="Final Grades", col="red", ylim=c(0,100))
hist(dat[dat$sex=="F", ]$G3, main="Female Students' Final Grades", xlab="Final Grades", col="lightblue", ylim=c(0,100))
```



### Variable Importance

The purpose of our report is to understand reasons why students are not passing their course. Our model has some significant predictor variables used to predict a student's final grade earned for the course taken. Below, we can see some of these variables that can effect the final grade negatively.  


```{r}
fit = rpart(G3 ~ studytime + freetime + goout + absences + Dalc + Walc + activities,  data=dat, method="class")
```


```{r}
par(mar = c(3, 6, 3, 3))
barplot(fit$variable.importance, main = "Variable Importance Plot", horiz = TRUE, las = 1, col = 'red4')
```

As we can see, Dalc (workday alcohol consumption) and absenses are the most detrimental for a student's final grade for the course. 


### Workday alcohol consumption

Since we know that workday alcohol consumption plays such a significant impact on a student's grade, we thought it would be best to explore this to gain an understanding of how students consume their alcohol. 

```{r}
par(mfrow=c(1, 2))
hist(dat$Dalc[dat$sex == "F"], col = "red4", main = "Female", xlab = "Alcohol Consumption (Scale of 1-5)", ylim = c(0, 300))
hist(dat$Dalc[dat$sex == "M"], col = "red4", main = "Male", xlab = "Alcohol Consumption (Scale of 1-5)", ylim = c(0, 300))

```

From the data, we see that there are more girls who consume alcohol at a level 1. Something we must remember is there are more girlsas opposed to males in the class, which may not be a full representation of how males drink their alcohol. 

```{r}
plot(density(dat$Walc), main = "Density Plot on Student Workday/Weekend Alcohol Consumption", col = "red4", xlim = c(0, 5), ylim = c(0, 2), xlab = "Scale of 1-5", lwd = 3) # red4: weekend
lines(density(dat$Dalc), col = "blue", lwd = 3) # blue: work day 
legend("topright", c("weekend consumption", "work day consumption"), pch = 15, col = c("red4", "blue"), inset = 0.05)


```

The density plot has two lines, one for weekend alcohol consumption, and another for work day consumption. We can conclude from our data that more students partake in consuming alcoholic beverages during a work day.


It's reasonable to believe that the higher number of absences a student has, the lower their final grade might be. As such, we'll take a look at the number of absences for this data. For a given number of absences, we'll see how many students were absent that number of times.


```{r}
par(mar=c(3, 10, 3, 3))
barplot(sort(table(dat$absences), decreasing=FALSE), horiz=TRUE, las=1, main="Frequency", col="firebrick", ylab="Number of Absences", xlim=c(0, 250))
grid(nx=25, ny=0, col="black")
```



```{r}
plot(density(dat$G1*5), main = "Student's grades", col = "red4", ylim=c(0,0.035), xlab = 'grade out of 100', xlim = c(0,100),lwd = 3,)
lines(density(dat$G2*5), col="darkgreen",lwd = 3)
lines(density(dat$G3*5), col="blue",lwd = 3)
legend("topleft", c("grade after 1st test","grade after 2nd test","final grade","dotted line passing failing"), pch = 15,col = c("red4","darkgreen", 'blue', 'white'),
inset = .05)
abline(v = 50, lty = 2, lwd = 1.5)
grid()
```


This density plot of three lines shows the distibution of grades for all the students. With the line red being the first test, the green line being the sceond, and blue line being the final grade. We pushed the grade from 20 points possible to 100. We can conclude that the average grade for students is around 12 out of 20 points (60%), which resembles a bell curve. 



# Splitting the data


```{r}
split = split_data(dat)
tr_dat = split[[1]]
te_dat = split[[2]]
```

```{r}
str(dat)
```


```{r}
summary(dat)
```

From above, we can see the average grade would be around 12. 

```{r}

te_dat$passingGrade = factor(ifelse(te_dat$G3 >= 12, "Pass", "Fail"))
tr_dat$passingGrade = factor(ifelse(tr_dat$G3 >= 12, "Pass", "Fail"))
```




```{r}

fit = rpart(passingGrade ~ absences + studytime + Dalc, data = te_dat, method = "class")
prp(fit, extra = 106, varlen = -10, main ="Classifiation for score over 60%", box.col = c("red", "green")[fit$frame$yval])


```


Through the tree above, we can see students who choose to study more than 2.5 hours should pass this course. Students who do not commit the study time or have more absenses increases the chance of not passing the class. This of course plays a significant role in a student's academic success for their class. 




```{r}

predicted = predict(fit, te_dat, type = "class")
actual = te_dat$passingGrade
confusionMatrix = table(actual, predicted)
confusionMatrix

```

Our success rate.

```{r}

mean(actual == predicted)

```

```{r}
te_errs = c()
tr_errs = c()
te_actual = te_dat$passingGrade
tr_sizes = seq(0, nrow(tr_dat), length.out = 20)
for(tr_size in tr_sizes){
  tr_dat1 = tr_dat[1:tr_size,]
  tr_actual = tr_dat1$passingGrade
  # tr_dat1$passingGrade = factor(ifelse(tr_dat1$G3 >= 12, "Pass", "Fail"))
  fit = rpart(passingGrade ~ absences + studytime + Dalc, data = tr_dat1, method = "class")
  # fit = naiveBayes(school ~ reason + address + guardian, data = tr_dat1)
  # error on training set
  tr_predicted = predict(fit, tr_dat1, type = 'class')
  err = sum(tr_actual != tr_predicted)/length(tr_predicted)
  tr_errs = c(tr_errs, err)
  #error on test set
  te_predicted = predict(fit, te_dat, type = 'class')
  err = sum(te_actual != te_predicted)/length(te_predicted)
  te_errs = c(te_errs, err)
}
plot(tr_sizes, tr_errs, type = 'b',lwd = 3, col = 'red',ylim = c(0,0.5))
lines(tr_sizes, te_errs, type = 'b',lwd = 3, col = 'blue')
legend("bottomright", c("training data", "testing data"), pch = 15, col = c("red", "blue"), inset = 0.05)


```

Our learning curve has a high bias

```{r}
tr_dat$freetime3 = factor(ifelse(tr_dat$freetime >= 3, yes = "fTime > 3", no = 'fTime < 3'))
fit = rpart(freetime3 ~ G3,data=tr_dat, method="class")
prp(fit, extra=106, varlen=-10,
main="Freetime over 3 on scale from 1-5 dependent on the final grade G3.",
box.col=c("palegreen", "pink")[fit$frame$yval])
```

```{r}
predicted = predict(fit, newdata=tr_dat, type ="class")
actuals = tr_dat$freetime3
conf_mtx = table(predicted, actuals)
conf_mtx
```

```{r}
succ_rate = mean(predicted == actuals)
round(succ_rate, 3)
```






```{r}
fit2 = naiveBayes(school ~ reason + address + guardian,data = tr_dat)
```

```{r}
fit2$tables$reason
```

```{r}
predicted = predict(fit2, newdata=te_dat)
actuals = te_dat$school
conf_mtx = table(predicted, actuals)
conf_mtx
```
```{r}
mean(predicted == actuals)
```
```{r}
te_errs = c()
tr_errs = c()
te_actual = te_dat$school
tr_sizes = seq(0, nrow(tr_dat)/2, length.out = 10)
for(tr_size in tr_sizes){
  tr_dat1 = tr_dat[1:tr_size,]
  tr_actual = tr_dat1$school
  fit2 = naiveBayes(school ~ reason + address + guardian, data = tr_dat1)
  # error on training set
  tr_predicted = predict(fit2, tr_dat1)
  err = sum(tr_actual != tr_predicted)/length(tr_predicted)
  tr_errs = c(tr_errs, err)
  #error on test set
  te_predicted = predict(fit2, te_dat)
  err = sum(te_actual != te_predicted)/length(te_predicted)
  te_errs = c(te_errs, err)
}
plot(tr_sizes, tr_errs, type = 'b',lwd = 3, col = 'red', ylim = c(0,0.5))
lines(tr_sizes, te_errs, type = 'b',lwd = 3, col = 'blue')
legend("bottomright", c("training data", "testing data"), pch = 15, col = c("red", "blue"), inset = 0.05)
```



```{r}
fit3 = naiveBayes(passingGrade ~ Dalc + studytime+ G1,data = tr_dat)
```

```{r}
fit3$tables$Dalc
```

```{r}
predicted = predict(fit3, newdata=te_dat)
actuals = te_dat$passingGrade
conf_mtx = table(predicted, actuals)
conf_mtx
```
```{r}
mean(predicted == actuals)
```
```{r}
te_errs = c()
tr_errs = c()
te_actual = te_dat$passingGrade
tr_sizes = seq(0, nrow(tr_dat)/3, length.out = 20)
for(tr_size in tr_sizes){
  tr_dat1 = tr_dat[1:tr_size,]
  tr_actual = tr_dat1$passingGrade
  fit3 = naiveBayes(passingGrade ~ Dalc + studytime + G1, data = tr_dat1)
  # error on training set
  tr_predicted = predict(fit3, tr_dat1)
  err = sum(tr_actual != tr_predicted)/length(tr_predicted)
  tr_errs = c(tr_errs, err)
  #error on test set
  te_predicted = predict(fit3, te_dat)
  err = sum(te_actual != te_predicted)/length(te_predicted)
  te_errs = c(te_errs, err)
}
plot(tr_sizes, tr_errs, type = 'b',lwd = 3, col = 'red', ylim = c(0,0.25))
lines(tr_sizes, te_errs, type = 'b',lwd = 3, col = 'blue')

legend("bottomright", c("training data", "testing data"), pch = 15, col = c("red", "blue"), inset = 0.05)

```



