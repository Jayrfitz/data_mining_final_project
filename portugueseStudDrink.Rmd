---
title: "Student Alcohol Consumption"
author: "Antonio Soto, Andrew Diesh, Jason Fitzgerald"
date: "April 22, 2017"
output: html_document
---
  
```{r global_options, include=FALSE}
knitr::opts_chunk$set(prompt=TRUE, comment="", echo=TRUE)
```

###**Objective**
Given the tools and techniques learned throughout the past four months we want to use these to analyze a dataset of our choosing and answer some question using prediction models.

After digging through different datasets we narrowed it down to a dataset on UFO sightings, one on salaries in the city of San Francisco, and one regarding student alcohol consumption.
After sifting through the UFO dataset we saw that there was little quantified data we could create models with. Features were mostly text descriptions of the object and approximate times of how long the sighting lasted. It was interesting on the surface but would prove difficult to model. Our San Francisco salary dataset only contained information on people who worked for the City of San Francisco. At first we thought it would contain data on all the technology jobs concentrated in the city. However, due to their private nature, those wages were not disclosed. Lastly the student dataset, while labeled as focusing on alcohol consumption, actually contained thirty different features to work with. Because of this we decided to pursue our project with this data.

This data set was gathered during the 2005-2006 school year from a survey of students in a Portuguese language course from the Alentejo region of Portugal. 
Paulo Cortez and Alice Silva went on to use this dataset for their study, _Using Data Mining to Predict Secondary School Student Performance_.
The data was acquired from Kaggle, a data science platform, at https://www.kaggle.com/uciml/student-alcohol-consumption. 

```{r}
library(rpart)
library(rpart.plot)
library(maptree)
library(e1071)

# jason
# dat = read.csv("/Users/jasonfitzgerald/Desktop/463Data/MiningProject/student-por.csv", stringsAsFactors = T)
# source("/Users/jasonfitzgerald/Desktop/463Data/MiningProject/class-util.R")
# source("/Users/jasonfitzgerald/Desktop/463Data/MiningProject/lin-regr-util.R")
# andrew
# dat = read.csv("/Users/AndrewDiesh/Desktop/student-por.csv", stringsAsFactors = T)
# source("/Users/AndrewDiesh/Desktop/class-util.R") 
# source("/Users/AndrewDiesh/Documents/CST\ 463/HW10/lin-regr-util.R")
# antonio
dat = read.csv("C:/Users/Antonio S/Documents/College/CSUMB-Spring'17/CST463-DataMining/FinalPro/student-por.csv", stringsAsFactors = T)
source("C:/Users/Antonio S/Documents/College/CSUMB-Spring'17/CST463-DataMining/FinalPro/class-util.R")
source("C:/Users/Antonio S/Documents/College/CSUMB-Spring'17/CST463-DataMining/FinalPro/lin-regr-util.R")
set.seed(123)
```


###**Data Exploration**
Now that we have our data we'll take a look at a few plots to see what data we're working with.

Our data revolves around secondary school students, therefore it would be useful to take a look at what ages are represented.
```{r}
dat$pieAges = ifelse(dat$age >= 20, '+20', dat$age)
ageOfStudents= table(dat$pieAges)

lbs = c(paste (names(table(dat$pieAges)), '-', round(table(dat$pieAges)/nrow(dat)*100,digit= 1), '%'))

pie(ageOfStudents, labels= lbs, main = 'Student Ages')
```

Our models will try to predict what the student's final grades will be.
Secondary and higher education in Portugal uses a 20-point grading scale.

18-20 indicates **excellent**, it's equivalent to an A+.

16-17.99 indicates **very good**, it's equivalent to an A.

14-15.99 indicates **good**, it's equivalent to a B.

10-13.99 indicates **sufficient**, it's equivalent to a C.

7-9.99 indicates **poor**, it's equivalent to an F.

1-6.99 indicates **very poor**, it's equivalent to an F.

Here we'll take a look at the grade distribution for male and female students. 
```{r}
par(mfrow=c(1, 2))
hist(dat[dat$sex=="M", ]$G3, main="Male Students' Final Grades", xlab="Final Grades", col="red", ylim=c(0,100))
hist(dat[dat$sex=="F", ]$G3, main="Female Students' Final Grades", xlab="Final Grades", col="lightblue", ylim=c(0,100))
```
It's reasonable to believe that the higher number of absences a student has, the lower their final grade might be. As such, we'll take a look at the number of absences for this data. For a given number of absences, we'll see how many students were absent that number of times.
```{r}
par(mar=c(3, 10, 3, 3))
barplot(sort(table(dat$absences), decreasing=FALSE), horiz=TRUE, las=1, main="Frequency", col="firebrick", ylab="Number of Absences", xlim=c(0, 250))
grid(nx=25, ny=0, col="black")
```









Our model has some significant predictor variables used to predict a student's final grade earned for the course taken. Below, we can see some of these variables that can effect the final grade negatively.  


```{r}
fit = rpart(G3 ~ studytime + freetime + goout + absences + Dalc + Walc + activities,  data=dat, method="class")
```



```{r}
par(mar = c(3, 15, 3, 3))
barplot(fit$variable.importance, main = "Variable Importance Plot", horiz = TRUE, las = 1, col = 'red4')
```

As we can see, Dalc (workday alcohol consumption) and absenses are the most detrimental for a student's final grade for the course. 

```{r}
plot(density(dat$Walc), main = "Density Plot on Student Workday/Weekend Alcohol Consumption", col = "red4", xlim = c(0, 5), ylim = c(0, 2), xlab = "Scale of 1-5", lwd = 3) # red4: weekend
lines(density(dat$Dalc), col = "blue", lwd = 3) # blue: work dat 
legend("topright", c("weekend consumption", "work day consumption"), pch = 15, col = c("red4", "blue"), inset = 0.05)


```

```{r}
plot(density(dat$G1*5), main = "Student's grades", col = "red4", ylim=c(0,0.035), xlab = 'grade out of 100', xlim = c(0,100),lwd = 3,)
lines(density(dat$G2*5), col="darkgreen",lwd = 3)
lines(density(dat$G3*5), col="blue",lwd = 3)
legend("topleft", c("grade after 1st test","grade after 2nd test","final grade","dotted line passing failing"), pch = 15,col = c("red4","darkgreen", 'blue', 'white'),
inset = .05)
abline(v = 50, lty = 2, lwd = 1.5)
grid()
```
This density plot of three lines shows the distibution of grades for all the students. With the line red being the first test, the green line being the sceond, and blue line being the final grade. We pushed the grade from 20 points possible to 100.

```{r}
split = split_data(dat)
tr_dat = split[[1]]
te_dat = split[[2]]
```

```{r}
str(dat)
```


```{r}
summary(dat)
```

```{r}

te_dat$passingGrade = factor(ifelse(te_dat$G3 >= 12, "Pass", "Fail"))
tr_dat$passingGrade = factor(ifelse(tr_dat$G3 >= 12, "Pass", "Fail"))
```




```{r}

fit = rpart(passingGrade ~ absences + studytime, data = te_dat, method = "class")
prp(fit, extra = 106, varlen = -10, main ="Classifiation for score over 60%", box.col = c("red", "green")[fit$frame$yval])


```






```{r}

predicted = predict(fit, te_dat, type = "class")
actual = te_dat$passingGrade
confusionMatrix = table(actual, predicted)
confusionMatrix

```


```{r}

mean(actual == predicted)

```

```{r}
te_errs = c()
tr_errs = c()
te_actual = te_dat$passingGrade
tr_sizes = seq(0, nrow(tr_dat), length.out = 20)
for(tr_size in tr_sizes){
  tr_dat1 = tr_dat[1:tr_size,]
  tr_actual = tr_dat1$passingGrade
  # tr_dat1$passingGrade = factor(ifelse(tr_dat1$G3 >= 12, "Pass", "Fail"))
  fit = rpart(passingGrade ~ absences + studytime, data = tr_dat1, method = "class")
  # fit = naiveBayes(school ~ reason + address + guardian, data = tr_dat1)
  # error on training set
  tr_predicted = predict(fit, tr_dat1, type = 'class')
  err = sum(tr_actual != tr_predicted)/length(tr_predicted)
  tr_errs = c(tr_errs, err)
  #error on test set
  te_predicted = predict(fit, te_dat, type = 'class')
  err = sum(te_actual != te_predicted)/length(te_predicted)
  te_errs = c(te_errs, err)
}
plot(tr_sizes, tr_errs, type = 'b',lwd = 3, col = 'red',ylim = c(0,0.5))
lines(tr_sizes, te_errs, type = 'b',lwd = 3, col = 'blue')


```

```{r}
tr_dat$freetime3 = factor(ifelse(tr_dat$freetime >= 3, yes = "fTime > 3", no = 'fTime < 3'))
fit = rpart(freetime3 ~ G3,data=tr_dat, method="class")
prp(fit, extra=106, varlen=-10,
main="Freetime over 3 on scale from 1-5 dependent on the final grade G3.",
box.col=c("palegreen", "pink")[fit$frame$yval])
```

```{r}
predicted = predict(fit, newdata=tr_dat, type ="class")
actuals = tr_dat$freetime3
conf_mtx = table(predicted, actuals)
conf_mtx
```

```{r}
succ_rate = mean(predicted == actuals)
round(succ_rate, 3)
```






```{r}
fit2 = naiveBayes(school ~ reason + address + guardian,data = tr_dat)
```

```{r}
fit2$tables$reason
```

```{r}
predicted = predict(fit2, newdata=te_dat)
actuals = te_dat$school
conf_mtx = table(predicted, actuals)
conf_mtx
```
```{r}
mean(predicted == actuals)
```
```{r}
te_errs = c()
tr_errs = c()
te_actual = te_dat$school
tr_sizes = seq(0, nrow(tr_dat)/2, length.out = 10)
for(tr_size in tr_sizes){
  tr_dat1 = tr_dat[1:tr_size,]
  tr_actual = tr_dat1$school
  fit2 = naiveBayes(school ~ reason + address + guardian, data = tr_dat1)
  # error on training set
  tr_predicted = predict(fit2, tr_dat1)
  err = sum(tr_actual != tr_predicted)/length(tr_predicted)
  tr_errs = c(tr_errs, err)
  #error on test set
  te_predicted = predict(fit2, te_dat)
  err = sum(te_actual != te_predicted)/length(te_predicted)
  te_errs = c(te_errs, err)
}
plot(tr_sizes, tr_errs, type = 'b',lwd = 3, col = 'red', ylim = c(0,0.5))
lines(tr_sizes, te_errs, type = 'b',lwd = 3, col = 'blue')


```



```{r}
fit3 = naiveBayes(passingGrade ~ Dalc + studytime+ G1,data = tr_dat)
```

```{r}
fit3$tables$absences
```

```{r}
predicted = predict(fit3, newdata=te_dat)
actuals = te_dat$passingGrade
conf_mtx = table(predicted, actuals)
conf_mtx
```
```{r}
mean(predicted == actuals)
```
```{r}
te_errs = c()
tr_errs = c()
te_actual = te_dat$passingGrade
tr_sizes = seq(0, nrow(tr_dat)/3, length.out = 20)
for(tr_size in tr_sizes){
  tr_dat1 = tr_dat[1:tr_size,]
  tr_actual = tr_dat1$passingGrade
  fit3 = naiveBayes(passingGrade ~ Dalc + studytime + G1, data = tr_dat1)
  # error on training set
  tr_predicted = predict(fit3, tr_dat1)
  err = sum(tr_actual != tr_predicted)/length(tr_predicted)
  tr_errs = c(tr_errs, err)
  #error on test set
  te_predicted = predict(fit3, te_dat)
  err = sum(te_actual != te_predicted)/length(te_predicted)
  te_errs = c(te_errs, err)
}
plot(tr_sizes, tr_errs, type = 'b',lwd = 3, col = 'red', ylim = c(0,0.25))
lines(tr_sizes, te_errs, type = 'b',lwd = 3, col = 'blue')


```



