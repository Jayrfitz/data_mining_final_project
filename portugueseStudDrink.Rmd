---
title: "Student Alcohol Consumption"
author: "Antonio Soto, Andrew Diesh, Jason Fitzgerald"
date: "April 22, 2017"
output: html_document
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(prompt=TRUE, comment="", echo=TRUE)
```

###**Objective**
Given the tools and techniques learned throughout the past four months we want to use these to analyze a dataset of our choosing and answer some question using prediction models.

After digging through different datasets we narrowed it down to a dataset on UFO sightings, one on salaries in the city of San Francisco, and one regarding student alcohol consumption.
After sifting through the UFO dataset we saw that there was little quantified data we could create models with. Features were mostly text descriptions of the object and approximate times of how long the sighting lasted. It was interesting on the surface but would prove difficult to model. Our San Francisco salary dataset only contained information on people who worked for the City of San Francisco. At first we thought it would contain data on all the technology jobs concentrated in the city. However, due to their private nature, those wages were not disclosed. Lastly the student dataset, while labeled as focusing on alcohol consumption, actually contained thirty different features to work with. Because of this we decided to pursue our project with this data.

This data set was gathered during the 2005-2006 school year from a survey of students in a Portuguese language course from the Alentejo region of Portugal. 
Paulo Cortez and Alice Silva went on to use this dataset for their study, _Using Data Mining to Predict Secondary School Student Performance_.
The data was acquired from Kaggle, a data science platform, at https://www.kaggle.com/uciml/student-alcohol-consumption. 

```{r}
# jason
#dat = read.csv("/Users/jasonfitzgerald/Desktop/463Data/MiningProject/student-por.csv", stringsAsFactors = T)
# andrew
# dat = read.csv("/Users/AndrewDiesh/Desktop/student-por.csv", stringsAsFactors = T)
# antonio
dat = read.csv("C:/Users/Antonio S/Documents/College/CSUMB-Spring'17/CST463-DataMining/FinalPro/student-por.csv", stringsAsFactors = T)
library(rpart)
library(rpart.plot)
library(maptree)
library(e1071)
# jason
#source("/Users/jasonfitzgerald/Desktop/463Data/MiningProject/class-util.R")
#source("/Users/jasonfitzgerald/Desktop/463Data/MiningProject/lin-regr-util.R")
# andrew
# source("/Users/AndrewDiesh/Desktop/class-util.R")
# source("/Users/AndrewDiesh/Documents/CST\ 463/HW10/lin-regr-util.R")
# antonio
source("C:/Users/Antonio S/Documents/College/CSUMB-Spring'17/CST463-DataMining/FinalPro/class-util.R")
source("C:/Users/Antonio S/Documents/College/CSUMB-Spring'17/CST463-DataMining/FinalPro/lin-regr-util.R")
set.seed(123)
```


###**Data Exploration**
Now that we have our data we'll take a look at a few plots to see what data we're working with.

Our data revolves around secondary school students, therefore it would be useful to take a look at what ages are represented.
```{r}
dat$pieAges = ifelse(dat$age >= 20, '+20', dat$age)
ageOfStudents= table(dat$pieAges)

lbs = c(paste (names(table(dat$pieAges)), '-', round(table(dat$pieAges)/nrow(dat)*100,digit= 1), '%'))

pie(ageOfStudents, labels= lbs, main = 'Student Ages')
```

Our models will try to predict what the student's final grades will be. Here we can see what the actual final grades in our data are.
```{r}
hist(dat$G3, main = "Student's Final Grades", xlab = "Final Grades. (Out of 20)", col = "red4")
```
It's reasonable to believe that the higher number of absences a student has, the lower their final grade might be. As such, we'll take a look at the number of absences for this data. For a given number of absences, we'll see how many students were absent that number of times.
```{r}
par(mar=c(3, 10, 3, 3))
barplot(sort(table(dat$absences), decreasing=FALSE), horiz=TRUE, las=1, main="Frequency", col="firebrick", ylab="Number of Absences", xlim=c(0, 250))
grid(nx=25, ny=0, col="black")
```











```{r}
fit = rpart(G3 ~ studytime + freetime + goout + absences + Dalc + Walc + activities,  data=dat, method="class")
```


```{r}
par(mar = c(3, 15, 3, 3))
barplot(fit$variable.importance, main = "Variable Importance Plot", horiz = TRUE, las = 1)
```

```{r}

plot(density(dat$Walc), main = "Student's Weekend Alcohol Consumption", col = "red4")


```

```{r}

# plot(studytime ~ age, data = dat, main = "Student's Weekend Alcohol Consumption", col = "red4")


```


```{r}
split = split_data(dat)
tr_dat = split[[1]]
te_dat = split[[2]]
```

```{r}
str(dat)
```


```{r}
summary(dat)
```

```{r}

te_dat$passingGrade = factor(ifelse(te_dat$G3 >= 12, "Pass", "Fail"))

```



```{r}

fit = rpart(passingGrade ~ absences + studytime, data = te_dat, method = "class")
prp(fit, extra = 106, varlen = -10, main ="classifiation for grades", box.col = c("red", "green")[fit$frame$yval])


```






```{r}

predicted = predict(fit, te_dat, type = "class")
actual = te_dat$passingGrade
confusionMatrix = table(actual, predicted)
confusionMatrix

length(predicted)
length(actual)

```


```{r}

mean(actual == predicted)

```

```{r}
fit = naiveBayes(school ~ reason + address + guardian,data = tr_dat)
```

```{r}
fit$tables$reason
```

```{r}
predicted = predict(fit, newdata=te_dat)
length(predicted)

actuals = te_dat$school
length(actuals)
```
```{r}
conf_mtx = table(predicted, actuals)
conf_mtx
```
```{r}
mean(predicted == actuals)
```


```{r}
tr_dat$freetime3 = factor(ifelse(tr_dat$freetime >= 3, yes = "freet >3", no = 'freet < 3'))
fit = rpart(freetime3 ~ G3,data=tr_dat, method="class")
prp(fit, extra=106, varlen=-10,
    main="Regreesion tree age over 50 and there max heart rates",
    box.col=c("palegreen", "pink")[fit$frame$yval])
```

```{r}
predicted = predict(fit, newdata=tr_dat, type ="class")
actuals = tr_dat$freetime3
conf_mtx = table(predicted, actuals)
conf_mtx
```

```{r}
succ_rate = mean(predicted == actuals)
round(succ_rate, 3)
```



G1
```{r}
table(tr_dat$G1)

```
G2
```{r}
table(tr_dat$G2)

```
G3
```{r}

table(tr_dat$G3)
```

