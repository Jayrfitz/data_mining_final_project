---
title: "Student Alcohol Consumption"
author: "Antonio Soto, Andrew Diesh, Jason Fitzgerald"
date: "April 22, 2017"
output: html_document
---
  
```{r global_options, include=FALSE}
knitr::opts_chunk$set(prompt=TRUE, comment="", echo=TRUE)
```

###**Objective**
Given the tools and techniques learned throughout the past four months we want to use these to analyze a dataset of our choosing and answer some question using prediction models.

After digging through different datasets we narrowed it down to a dataset on UFO sightings, one on salaries in the city of San Francisco, and one regarding student alcohol consumption.
After sifting through the UFO dataset we saw that there was little quantified data we could create models with. Features were mostly text descriptions of the object and approximate times of how long the sighting lasted. It was interesting on the surface but would prove difficult to model. Our San Francisco salary dataset only contained information on people who worked for the City of San Francisco. At first we thought it would contain data on all the technology jobs concentrated in the city. However, due to their private nature, those wages were not disclosed. Lastly the student dataset, while labeled as focusing on alcohol consumption, actually contained thirty different features to work with. Because of this we decided to pursue our project with this data.

This data set was gathered during the 2005-2006 school year from a survey of students in a Portuguese language course from the Alentejo region of Portugal. 
Paulo Cortez and Alice Silva went on to use this dataset for their study, _Using Data Mining to Predict Secondary School Student Performance_.
The data was acquired from Kaggle, a data science platform, at https://www.kaggle.com/uciml/student-alcohol-consumption. 

```{r}
# jason
dat = read.csv("/Users/jasonfitzgerald/Desktop/463Data/MiningProject/student-por.csv", stringsAsFactors = T)
# andrew
# dat = read.csv("/Users/AndrewDiesh/Desktop/student-por.csv", stringsAsFactors = T)
# antonio
# dat = read.csv("C:/Users/Antonio S/Documents/College/CSUMB-Spring'17/CST463-DataMining/FinalPro/student-por.csv", stringsAsFactors = T)
library(rpart)
library(rpart.plot)
library(maptree)
library(e1071)
# jason
source("/Users/jasonfitzgerald/Desktop/463Data/MiningProject/class-util.R")
source("/Users/jasonfitzgerald/Desktop/463Data/MiningProject/lin-regr-util.R")
# andrew
# source("/Users/AndrewDiesh/Desktop/class-util.R")
# source("/Users/AndrewDiesh/Documents/CST\ 463/HW10/lin-regr-util.R")
# antonio
# source("C:/Users/Antonio S/Documents/College/CSUMB-Spring'17/CST463-DataMining/FinalPro/class-util.R")
# source("C:/Users/Antonio S/Documents/College/CSUMB-Spring'17/CST463-DataMining/FinalPro/lin-regr-util.R")
set.seed(123)
```


###**Data Exploration**
Now that we have our data we'll take a look at a few plots to see what data we're working with.

Our data revolves around secondary school students, therefore it would be useful to take a look at what ages are represented.
```{r}
dat$pieAges = ifelse(dat$age >= 20, '+20', dat$age)
ageOfStudents= table(dat$pieAges)

lbs = c(paste (names(table(dat$pieAges)), '-', round(table(dat$pieAges)/nrow(dat)*100,digit= 1), '%'))

pie(ageOfStudents, labels= lbs, main = 'Student Ages')
```

Our models will try to predict what the student's final grades will be. Here we can see what the actual final grades in our data are.
```{r}
hist(dat$G3, main = "Student's Final Grades", xlab = "Final Grades. (Out of 20)", col = "red4")
```
It's reasonable to believe that the higher number of absences a student has, the lower their final grade might be. As such, we'll take a look at the number of absences for this data. For a given number of absences, we'll see how many students were absent that number of times.
```{r}
par(mar=c(3, 10, 3, 3))
barplot(sort(table(dat$absences), decreasing=FALSE), horiz=TRUE, las=1, main="Frequency", col="firebrick", ylab="Number of Absences", xlim=c(0, 250))
grid(nx=25, ny=0, col="black")
```











```{r}
fit = rpart(G3 ~ studytime + freetime + goout + absences + Dalc + Walc + activities,  data=dat, method="class")
```


```{r}
par(mar = c(3, 15, 3, 3))
barplot(fit$variable.importance, main = "Variable Importance Plot", horiz = TRUE, las = 1, col = 'red4')
```

```{r}
plot(density(dat$Walc), main = "Density Plot on Student Workday/Weekend Alcohol Consumption", col = "red4", xlim = c(0, 5), ylim = c(0, 2), xlab = "Scale of 1-5") # red4: weekend
lines(density(dat$Dalc), col = "blue") # blue: work dat 
legend("topright", c("weekend consumption", "work day consumption"), pch = 15, col = c("red4", "blue"), inset = 0.05)


```

```{r}
plot(density(dat$G1*5), main = "Student's grades", col = "red4", ylim=c(0,0.035), xlab = 'grade out of 100', xlim=c(0,100),lwd = 3)
lines(density(dat$G2*5), col="darkgreen",lwd = 3)
lines(density(dat$G3*5), col="blue",lwd = 3)
legend("topleft", c("grade after 1st test","grade after 2nd test","final grade"), pch = 15,col = c("red4","darkgreen", 'blue'),
inset = .05)
```


```{r}
split = split_data(dat)
tr_dat = split[[1]]
te_dat = split[[2]]
```

```{r}
str(dat)
```


```{r}
summary(dat)
```

```{r}

te_dat$passingGrade = factor(ifelse(te_dat$G3 >= 12, "Pass", "Fail"))
tr_dat$passingGrade = factor(ifelse(tr_dat$G3 >= 12, "Pass", "Fail"))
```



```{r}

fit = rpart(passingGrade ~ absences + studytime, data = te_dat, method = "class")
prp(fit, extra = 106, varlen = -10, main ="classifiation for grades", box.col = c("red", "green")[fit$frame$yval])


```






```{r}

predicted = predict(fit, te_dat, type = "class")
actual = te_dat$passingGrade
confusionMatrix = table(actual, predicted)
confusionMatrix

```


```{r}

mean(actual == predicted)

```

```{r}
te_errs = c()
tr_errs = c()
te_actual = te_dat$passingGrade
tr_sizes = seq(100, nrow(tr_dat), length.out = 20)
for(tr_size in tr_sizes){
tr_dat1 = tr_dat[1:tr_size,]
tr_actual = tr_dat1$passingGrade
tr_dat1$passingGrade = factor(ifelse(tr_dat1$G3 >= 12, "Pass", "Fail"))
fit = rpart(passingGrade ~ absences + studytime, data = tr_dat1, method = "class")
# fit = naiveBayes(school ~ reason + address + guardian, data = tr_dat1)
# error on training set
tr_predicted = predict(fit, tr_dat1)
err = sum(tr_actual != tr_predicted)/length(tr_predicted)
tr_errs = c(tr_errs, err)
#error on test set
te_predicted = predict(fit, te_dat)
err = sum(te_actual != te_predicted)/length(te_predicted)
te_errs = c(te_errs, err)
}
plot(tr_sizes, tr_errs, type = 'l',lwd = 10, col = 'red')
lines(tr_sizes, te_errs, type = 'l',lwd = 3, col = 'blue')


```

```{r}
tr_dat$freetime3 = factor(ifelse(tr_dat$freetime >= 3, yes = "fTime > 3", no = 'fTime < 3'))
fit = rpart(freetime3 ~ G3,data=tr_dat, method="class")
prp(fit, extra=106, varlen=-10,
main="Freetime over 3 on scale from 1-5 dependent on the final grade G3.",
box.col=c("palegreen", "pink")[fit$frame$yval])
```

```{r}
predicted = predict(fit, newdata=tr_dat, type ="class")
actuals = tr_dat$freetime3
conf_mtx = table(predicted, actuals)
conf_mtx
```

```{r}
succ_rate = mean(predicted == actuals)
round(succ_rate, 3)
```






```{r}
fit2 = naiveBayes(school ~ reason + address + guardian,data = tr_dat)
```

```{r}
fit2$tables$reason
```

```{r}
predicted = predict(fit2, newdata=te_dat)
actuals = te_dat$school
conf_mtx = table(predicted, actuals)
conf_mtx
```
```{r}
mean(predicted == actuals)
```
```{r}
te_errs = c()
tr_errs = c()
te_actual = te_dat$school
tr_sizes = seq(100, nrow(tr_dat), length.out = 20)
for(tr_size in tr_sizes){
tr_dat1 = tr_dat[1:tr_size,]
tr_actual = tr_dat1$school
fit2 = naiveBayes(school ~ reason + address + guardian, data = tr_dat1)
# error on training set
tr_predicted = predict(fit2, tr_dat1)
err = sum(tr_actual != tr_predicted)/length(tr_predicted)
tr_errs = c(tr_errs, err)
#error on test set
te_predicted = predict(fit2, te_dat)
err = sum(te_actual != te_predicted)/length(te_predicted)
te_errs = c(te_errs, err)
}
plot(tr_sizes, tr_errs, type = 'l',lwd = 3, col = 'red', ylim = c(0.22,0.29))
lines(tr_sizes, te_errs, type = 'l',lwd = 3, col = 'blue')


```



```{r}
fit3 = naiveBayes(passingGrade ~ absences + Dalc + studytime+ G1 + G2,data = tr_dat)
```

```{r}
fit3$tables$absences
```

```{r}
predicted = predict(fit3, newdata=te_dat)
actuals = te_dat$passingGrade
conf_mtx = table(predicted, actuals)
conf_mtx
```
```{r}
mean(predicted == actuals)
```
```{r}
te_errs = c()
tr_errs = c()
te_actual = te_dat$passingGrade
tr_sizes = seq(100, nrow(tr_dat), length.out = 20)
for(tr_size in tr_sizes){
tr_dat1 = tr_dat[1:tr_size,]
tr_actual = tr_dat1$passingGrade
fit3 = naiveBayes(passingGrade ~ absences + Dalc + studytime + G1 + G2, data = tr_dat1)
# error on training set
tr_predicted = predict(fit3, tr_dat1)
err = sum(tr_actual != tr_predicted)/length(tr_predicted)
tr_errs = c(tr_errs, err)
#error on test set
te_predicted = predict(fit3, te_dat)
err = sum(te_actual != te_predicted)/length(te_predicted)
te_errs = c(te_errs, err)
}
plot(tr_sizes, tr_errs, type = 'l',lwd = 3, col = 'red', ylim = c(0,0.20))
lines(tr_sizes, te_errs, type = 'l',lwd = 3, col = 'blue')


```



